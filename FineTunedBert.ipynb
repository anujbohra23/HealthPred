{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1c533ab-4907-4397-a4bd-11c8ac50fbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from functools import partial\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset , load_metric\n",
    "from transformers import pipeline\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df57034d-bc42-472f-abfd-04a797218141",
   "metadata": {},
   "source": [
    "Let's set the IDs for the model and the dataset. We will download both of them from the Hugging Face Hub, using the `datasets` and `transformers` libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9627ab22-efd5-4270-9011-547028913250",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ID = \"anuj/squad\"\n",
    "MODEL_ID = \"google-bert/bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba00863f-6db4-40ae-8a60-19abba7b244a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the SQuAD dataset\n",
    "data = load_dataset(DATASET_ID)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6500541f-d9a1-405d-89e3-9eaf645aad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the BERT tokenizer\n",
    "# set `clean_up_tokenization_spaces` to False to keep the tokenization spaces\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_ID, clean_up_tokenization_spaces=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b7f09c-48f9-4196-83df-4b2fedc77ea9",
   "metadata": {},
   "source": [
    "Next, let's structure the examples in the desired format. First, we tokenize the questions and the context. Then, using the answer and sequence IDs (or segment IDs, as mentioned in the introduction), we identify the start and end positions of the answer within the context. Finally, we will apply the preprocessing function to each row in the `train` set and discard the columns we don't need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d122e349-613c-4353-9896-856f15daf4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_train_examples(examples, tokenizer, max_length, stride):\n",
    "    \"\"\"Process the training split of the SQuAD dataset.\n",
    "    \n",
    "    Process the training split of the SQuAD dataset to include tokenized questions\n",
    "    and context, as well as the start and end positions of the answer within the context.\n",
    "    \n",
    "    Args:\n",
    "        examples: A row from the dataset containing an example.\n",
    "        tokenizer: The BERT tokenizer to be used.\n",
    "        max_length: The maximum length of the input sequence. If exceeded, truncate the second\n",
    "            sentence of a pair (or a batch of pairs) to fit within the limit.\n",
    "        stride: The number of tokens to retain from the end of a truncated sequence, allowing\n",
    "            for overlap between truncated and overflowing sequences.\n",
    "    \n",
    "    Returns:\n",
    "        The processed example.\n",
    "    \"\"\"\n",
    "    # Tokenize the questions and context sequences\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "      questions,\n",
    "      examples[\"context\"],\n",
    "      truncation=\"only_second\",\n",
    "      padding=\"max_length\",\n",
    "      stride=stride,\n",
    "      max_length=max_length,\n",
    "      return_offsets_mapping=True,\n",
    "      return_overflowing_tokens=True,\n",
    "    )\n",
    "\n",
    "    answers = examples[\"answers\"]\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    # find the start and end positions of the answer within the context\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i]\n",
    "        answer = answers[sample_idx]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # if the answer is not fully inside the context, label it (0, 0)\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66c25935-e71a-4058-8381-228c7d1c07bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "    num_rows: 88524\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_train_data = partial(\n",
    "    preprocess_train_examples, tokenizer=tokenizer, max_length=384, stride=128)\n",
    "processed_train_data = data[\"train\"].map(preprocess_train_data, batched=True, remove_columns=data[\"train\"].column_names)\n",
    "processed_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aae4bcf1-db3e-4162-88fc-ee04753ec455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_valid_examples(examples, tokenizer, max_length, stride):\n",
    "    \"\"\"Process the validation split of the SQuAD dataset.\n",
    "    \n",
    "    Process the training split of the SQuAD dataset to include the unique ID of each row,\n",
    "    the tokenized questions and context, as well as the start and end positions of the answer\n",
    "    within the context.\n",
    "    \n",
    "    Args:\n",
    "        examples: A row from the dataset containing an example.\n",
    "        tokenizer: The BERT tokenizer to be used.\n",
    "        max_length: The maximum length of the input sequence. If exceeded, truncate the second\n",
    "            sentence of a pair (or a batch of pairs) to fit within the limit.\n",
    "        stride: The number of tokens to retain from the end of a truncated sequence, allowing\n",
    "            for overlap between truncated and overflowing sequences.\n",
    "    \n",
    "    Returns:\n",
    "        The processed example.\n",
    "    \"\"\"\n",
    "    # Tokenize the questions and context sequences\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "      questions,\n",
    "      examples[\"context\"],\n",
    "      truncation=\"only_second\",\n",
    "      padding=\"max_length\",\n",
    "      stride=stride,\n",
    "      max_length=max_length,\n",
    "      return_offsets_mapping=True,\n",
    "      return_overflowing_tokens=True,\n",
    "    )\n",
    "    \n",
    "    example_ids = []\n",
    "    answers = examples[\"answers\"]\n",
    "    offset_mapping = inputs[\"offset_mapping\"]\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    # find the start and end positions of the answer within the context\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i]\n",
    "        example_ids.append(examples[\"id\"][sample_idx])\n",
    "        answer = answers[sample_idx]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        \n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        inputs[\"offset_mapping\"][i] = [\n",
    "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "        ]\n",
    "\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # if the answer is not fully inside the context, label it (0, 0)\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"example_id\"] = example_ids  # keep the unique ID of the example\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81c1c7ba-151d-48cd-9988-fd8fc8132a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'example_id', 'start_positions', 'end_positions'],\n",
       "    num_rows: 10784\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_valid_data = partial(\n",
    "    preprocess_valid_examples, tokenizer=tokenizer, max_length=384, stride=128)\n",
    "processed_valid_data = data[\"validation\"].map(preprocess_valid_data, batched=True, remove_columns=data[\"validation\"].column_names)\n",
    "processed_valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "470c2f1b-0ae0-40f2-9ea3-0145f41a81bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cfecbba-59a9-4c07-8b27-f8610fe9acef",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./checkpoints',\n",
    "    logging_dir='./logs',\n",
    "    eval_strategy=\"steps\",\n",
    "    logging_steps=500,\n",
    "    logging_strategy=\"steps\",\n",
    "    save_steps=2000,\n",
    "    save_strategy=\"steps\",\n",
    "    learning_rate=3e-5,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    bf16=True,\n",
    "    per_device_train_batch_size=48,\n",
    "    per_device_eval_batch_size=96,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2155825b-0a50-487a-b8ba-dc5400330921",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=processed_train_data,\n",
    "    eval_dataset=processed_valid_data,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a784484-7182-49c9-a3dc-47479c99ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(start_logits, end_logits, features, examples, n_best=20, max_answer_length=50):\n",
    "    \"\"\"Compute the Exact Match (EM) and F1 score for the model's predictions.\n",
    "    \n",
    "    Reconstruct the actual text of the answer from the model's predictions and compare\n",
    "    it to the ground truth for the validation dataset.\n",
    "    \n",
    "    Args:\n",
    "        start_logits: Logits predicting the start position of the answer.\n",
    "        end_logits: Logits predicting the end position of the answer.\n",
    "        features: The processed validation dataset.\n",
    "        examples: The raw validation dataset.\n",
    "        n_best: The top-k answers to consider.\n",
    "        max_answer_length: The maximum length of an answer to consider.\n",
    "    \n",
    "    Returns:\n",
    "        The Exact Match (EM) and F1 score for the validation dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    metric = evaluate.load(\"squad\")\n",
    "\n",
    "    # keep a dictionary that maps examples to predictions through unique IDs\n",
    "    example_to_features = collections.defaultdict(list)\n",
    "    for idx, feature in enumerate(features):\n",
    "        example_to_features[feature[\"example_id\"]].append(idx)\n",
    "\n",
    "    predicted_answers = []\n",
    "    for example in tqdm(examples):\n",
    "        example_id = example[\"id\"]\n",
    "        context = example[\"context\"]\n",
    "        answers = []\n",
    "\n",
    "        # loop through all features associated with that example\n",
    "        for feature_index in example_to_features[example_id]:\n",
    "            start_logit = start_logits[feature_index]\n",
    "            end_logit = end_logits[feature_index]\n",
    "            offsets = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            # keep a list of the top-k best predictions for the start and end position indexes\n",
    "            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # skip answers that are not fully in the context\n",
    "                    if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                        continue\n",
    "                    # skip answers with a length that is either < 0 or > max_answer_length\n",
    "                    if (\n",
    "                        end_index < start_index\n",
    "                        or end_index - start_index + 1 > max_answer_length\n",
    "                    ):\n",
    "                        continue\n",
    "\n",
    "                    # reconstruct the answer considering each prediction for the start and end positions \n",
    "                    answer = {\n",
    "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
    "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
    "                    }\n",
    "                    answers.append(answer)\n",
    "\n",
    "        # select the answer with the best score based on the logit scores\n",
    "        if len(answers) > 0:\n",
    "            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "            # create a list with the predictions that contains the IDs and actual text\n",
    "            # see: https://huggingface.co/spaces/evaluate-metric/squad\n",
    "            predicted_answers.append(\n",
    "                {\"id\": example_id, \"prediction_text\": best_answer[\"text\"]}\n",
    "            )\n",
    "        else:\n",
    "            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n",
    "\n",
    "    # create a list with the labels that contains the IDs and actual text\n",
    "    # see: https://huggingface.co/spaces/evaluate-metric/squad\n",
    "    theoretical_answers = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in examples]\n",
    "    return metric.compute(predictions=predicted_answers, references=theoretical_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a2900c9-deb2-4ce1-92ed-83083fa6e228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10570/10570 [00:05<00:00, 2100.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'exact_match': 0.12298959318826869, 'f1': 7.6225301494760656}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, _, _ = trainer.predict(processed_valid_data)\n",
    "start_logits, end_logits = predictions\n",
    "compute_metrics(start_logits, end_logits, processed_valid_data, data[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c57d8bd-c894-4582-a313-18357c543e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: \n",
      "\n",
      " During Reconstruction and the Gilded Age, Jacksonville and nearby St. Augustine became popular winter resorts for the rich and famous. Visitors arrived by steamboat and later by railroad. President Grover Cleveland attended the Sub-Tropical Exposition in the city on February 22, 1888 during his trip to Florida. This highlighted the visibility of the state as a worthy place for tourism. The city's tourism, however, was dealt major blows in the late 19th century by yellow fever outbreaks. In addition, extension of the Florida East Coast Railway further south drew visitors to other areas. From 1893 to 1938 Jacksonville was the site of the Florida Old Confederate Soldiers and Sailors Home with a nearby cemetery. \n",
      "\n",
      "Question: \n",
      "\n",
      " Which US President visited Jacksonville in 1888? \n",
      "\n",
      "Answer: \n",
      "\n",
      " city on February 22, 1888 \n",
      "\n",
      "--- \n",
      "\n",
      "Context: \n",
      "\n",
      " Several commemorative events take place every year. Gatherings of thousands of people on the banks of the Vistula on Midsummer’s Night for a festival called Wianki (Polish for Wreaths) have become a tradition and a yearly event in the programme of cultural events in Warsaw. The festival traces its roots to a peaceful pagan ritual where maidens would float their wreaths of herbs on the water to predict when they would be married, and to whom. By the 19th century this tradition had become a festive event, and it continues today. The city council organize concerts and other events. Each Midsummer’s Eve, apart from the official floating of wreaths, jumping over fires, looking for the fern flower, there are musical performances, dignitaries' speeches, fairs and fireworks by the river bank. \n",
      "\n",
      "Question: \n",
      "\n",
      " How man people gather along the banks of the Vistula for the Wianki festival? \n",
      "\n",
      "Answer: \n",
      "\n",
      " ritual where maidens would float their wreaths of herbs \n",
      "\n",
      "--- \n",
      "\n",
      "Context: \n",
      "\n",
      " NE1fm launched on 8 June 2007, the first full-time community radio station in the area. Newcastle Student Radio is run by students from both of the city's universities, broadcasting from Newcastle University's student's union building during term time. Radio Tyneside has been the voluntary hospital radio service for most hospitals across Newcastle and Gateshead since 1951, broadcasting on Hospedia  and online. The city also has a Radio Lollipop station based at the Great North Children's Hospital in the Newcastle Royal Victoria Infirmary. \n",
      "\n",
      "Question: \n",
      "\n",
      " Where does the Newcastle Student Radio station broadcast from during terms? \n",
      "\n",
      "Answer: \n",
      "\n",
      " student's union building during term time. Radio Tyneside \n",
      "\n",
      "--- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_indexes = np.random.randint(0, len(data[\"validation\"]), 3)\n",
    "subdataset = data[\"validation\"].select(random_indexes)\n",
    "qa_pipe_untrained = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, device='cuda')\n",
    "\n",
    "for row in subdataset:\n",
    "    context = row[\"context\"]\n",
    "    question = row[\"question\"]\n",
    "    answer = qa_pipe_untrained(question=question, context=context)\n",
    "\n",
    "    print(f\"Context: \\n\\n {context} \\n\")\n",
    "    print(f\"Question: \\n\\n {question} \\n\")\n",
    "    print(f\"Answer: \\n\\n {answer['answer']} \\n\")\n",
    "    print(\"--- \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feee0071-2e17-4046-978e-f292bc25fb3d",
   "metadata": {},
   "source": [
    "Let's fine-tune BERT so it gives better answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "789143f0-952e-420b-b0cb-f535a49d1332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3690' max='3690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3690/3690 49:41, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.927400</td>\n",
       "      <td>1.246485</td>\n",
       "      <td>0.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.261800</td>\n",
       "      <td>1.104862</td>\n",
       "      <td>0.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.144400</td>\n",
       "      <td>1.058678</td>\n",
       "      <td>0.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.009900</td>\n",
       "      <td>1.035863</td>\n",
       "      <td>0.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.847600</td>\n",
       "      <td>1.029328</td>\n",
       "      <td>0.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.837600</td>\n",
       "      <td>1.022908</td>\n",
       "      <td>0.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.836200</td>\n",
       "      <td>1.014414</td>\n",
       "      <td>0.001300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3690, training_loss=1.1079473355921303, metrics={'train_runtime': 2982.1319, 'train_samples_per_second': 59.37, 'train_steps_per_second': 1.237, 'total_flos': 3.4696551139946496e+16, 'train_loss': 1.1079473355921303, 'epoch': 2.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0284cf6-0dc9-4f4a-9f4c-ea31f2fcecb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10570/10570 [00:05<00:00, 2004.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'exact_match': 79.81078524124882, 'f1': 87.49254032175962}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, _, _ = trainer.predict(processed_valid_data)\n",
    "start_logits, end_logits = predictions\n",
    "compute_metrics(start_logits, end_logits, processed_valid_data, data[\"validation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82c8c9a-51ff-4b0a-b7a1-4f722cdd4d8c",
   "metadata": {},
   "source": [
    "Let's also provide an answer for the same random samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc5f9150-bbfc-4779-bb8e-08b030ff25c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: \n",
      "\n",
      " During Reconstruction and the Gilded Age, Jacksonville and nearby St. Augustine became popular winter resorts for the rich and famous. Visitors arrived by steamboat and later by railroad. President Grover Cleveland attended the Sub-Tropical Exposition in the city on February 22, 1888 during his trip to Florida. This highlighted the visibility of the state as a worthy place for tourism. The city's tourism, however, was dealt major blows in the late 19th century by yellow fever outbreaks. In addition, extension of the Florida East Coast Railway further south drew visitors to other areas. From 1893 to 1938 Jacksonville was the site of the Florida Old Confederate Soldiers and Sailors Home with a nearby cemetery. \n",
      "\n",
      "Question: \n",
      "\n",
      " Which US President visited Jacksonville in 1888? \n",
      "\n",
      "Answer: \n",
      "\n",
      " Grover Cleveland \n",
      "\n",
      "--- \n",
      "\n",
      "Context: \n",
      "\n",
      " Several commemorative events take place every year. Gatherings of thousands of people on the banks of the Vistula on Midsummer’s Night for a festival called Wianki (Polish for Wreaths) have become a tradition and a yearly event in the programme of cultural events in Warsaw. The festival traces its roots to a peaceful pagan ritual where maidens would float their wreaths of herbs on the water to predict when they would be married, and to whom. By the 19th century this tradition had become a festive event, and it continues today. The city council organize concerts and other events. Each Midsummer’s Eve, apart from the official floating of wreaths, jumping over fires, looking for the fern flower, there are musical performances, dignitaries' speeches, fairs and fireworks by the river bank. \n",
      "\n",
      "Question: \n",
      "\n",
      " How man people gather along the banks of the Vistula for the Wianki festival? \n",
      "\n",
      "Answer: \n",
      "\n",
      " thousands \n",
      "\n",
      "--- \n",
      "\n",
      "Context: \n",
      "\n",
      " NE1fm launched on 8 June 2007, the first full-time community radio station in the area. Newcastle Student Radio is run by students from both of the city's universities, broadcasting from Newcastle University's student's union building during term time. Radio Tyneside has been the voluntary hospital radio service for most hospitals across Newcastle and Gateshead since 1951, broadcasting on Hospedia  and online. The city also has a Radio Lollipop station based at the Great North Children's Hospital in the Newcastle Royal Victoria Infirmary. \n",
      "\n",
      "Question: \n",
      "\n",
      " Where does the Newcastle Student Radio station broadcast from during terms? \n",
      "\n",
      "Answer: \n",
      "\n",
      " Newcastle University's student's union building \n",
      "\n",
      "--- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "qa_pipe = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, device='cuda')\n",
    "\n",
    "for row in subdataset:\n",
    "    context = row[\"context\"]\n",
    "    question = row[\"question\"]\n",
    "    answer = qa_pipe(question=question, context=context)\n",
    "\n",
    "    print(f\"Context: \\n\\n {context} \\n\")\n",
    "    print(f\"Question: \\n\\n {question} \\n\")\n",
    "    print(f\"Answer: \\n\\n {answer['answer']} \\n\")\n",
    "    print(\"--- \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
